---
id: create-chat-completion
title: "Creates a model response for the given chat conversation"
description: "The Chat Completions API provides an OpenAI-compatible interface for generating model responses in multi-turn chat conversations. This API enables you to integrate our language models directly into applications designed to work with the OpenAI Chat Completions format, making it easy to leverage Vectara capabilities with minimal changes to existing tools or code."
sidebar_label: "Creates a model response for the given chat conversation"
hide_title: true
hide_table_of_contents: true
api: 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
sidebar_class_name: "post api-method"
info_path: docs/rest-api/vectara-rest-api-v-2
custom_edit_url: null
---

import MethodEndpoint from "@theme/ApiExplorer/MethodEndpoint";
import ParamsDetails from "@theme/ParamsDetails";
import RequestSchema from "@theme/RequestSchema";
import StatusCodes from "@theme/StatusCodes";
import OperationTabs from "@theme/OperationTabs";
import TabItem from "@theme/TabItem";
import Heading from "@theme/Heading";

<Heading
  as={"h1"}
  className={"openapi__heading"}
  children={"Creates a model response for the given chat conversation"}
>
</Heading>

<MethodEndpoint
  method={"post"}
  path={"/v2/llms/chat/completions"}
  context={"endpoint"}
>
  
</MethodEndpoint>



The Chat Completions API provides an OpenAI-compatible interface for generating model responses in multi-turn chat conversations. This API enables you to integrate our language models directly into applications designed to work with the OpenAI Chat Completions format, making it easy to leverage Vectara capabilities with minimal changes to existing tools or code.

Use this API to enable interactive chat experiences that support context-aware responses, streaming output, and token usage tracking.

The request includes a series of chat messages and optional parameters that control the behavior and structure of the model response. The request body must include the `messages` parameter, an array of message objects (role, content) representing the full conversation so far.

### Streaming responses

If the `stream` parameter is set to `true`, the response appears as a series of text/event-stream parts (also known as chunks). Each chunk includes a `delta` field showing the incremental message update.

### Example request

This example sends a simple chat conversation to the API, asking the assistant for the capital of France. The request includes a system prompt, a user message, and a temperature setting for response variability.
```json
{
  "model": "chat-model-001","messages": [{ "role": "system", "content": "You are a helpful assistant." },
  { "role": "user", "content": "What is the capital of France?" }
],
"temperature": 0.7,
"stream": false
}
```

### Example response
The response includes a generated reply from the assistant, along with token usage statistics. In this example, the model returns a direct answer to a user question.
```json
{
"id": "chatcmpl-abc123",}
"object": "chat.completion",
"created": 1712454830,
"model": "chat-model-001",
"choices": [
  {
    "index": 0,
    "message": {
      "role": "assistant",
      "content": "The capital of France is Paris."
  },
    "finish_reason": "stop"
  }
],
"usage": {
  "prompt_tokens": 21,
  "completion_tokens": 9,
  "total_tokens": 30
  } 
} 
```
If the input summary is accurate, the `corrected_summary` matches the `original_summary`.


<Heading
  id={"request"}
  as={"h2"}
  className={"openapi-tabs__heading"}
  children={"Request"}
>
</Heading>

<ParamsDetails
  parameters={[{"in":"header","name":"Request-Timeout","description":"The API will make a best effort to complete the request in the specified seconds or time out.","schema":{"type":"integer","minimum":1},"required":false},{"in":"header","name":"Request-Timeout-Millis","description":"The API will make a best effort to complete the request in the specified milliseconds or time out.","schema":{"type":"integer","minimum":1}}]}
>
  
</ParamsDetails>

<RequestSchema
  title={"Body"}
  body={{"required":true,"content":{"application/json":{"schema":{"description":"The request object for creating a chat completion with an OpenAI-compatible interface. This object is compatible with OpenAI's chat completion schema and supports customizable parameters for response generation.","type":"object","required":["messages","model"],"properties":{"model":{"type":"string","description":"The ID of the model to use. This field is required."},"messages":{"type":"array","description":"An ordered array of messages that represent the full context of the conversation to date. Each message includes a `role` and `content`.","minItems":1,"items":{"description":"A message in the chat completion request, representing part of the conversation.","type":"object","required":["role","content"],"properties":{"role":{"type":"string","description":"The role of the author of this message. Common values include 'system', 'user', 'assistant', 'function', and 'tool'."},"content":{"description":"The contents of the message. Follows the exact format of the content field in the OpenAI Chat Completions API (https://platform.openai.com/docs/api-reference/chat/create). Can be a string for text-only messages, or an array of content parts for multimodal messages with text and images."},"name":{"type":"string","description":"The name of the author of this message, used to connect messages in a conversation."}},"title":"ChatCompletionRequestMessage"}},"stream":{"type":"boolean","description":"Optional. When set to `true`, the API streams partial message deltas as they become available, similar to ChatGPT's streaming mode.","default":false},"response_format":{"description":"Specifies the output format for the model response.","type":"object","required":["type"],"properties":{"type":{"description":"The format type. Use 'json_schema' for structured outputs, 'json_object' for basic JSON mode, or 'text' for plain text.","type":"string","default":"text","enum":["json_schema","json_object","text"]},"json_schema":{"description":"The JSON schema specification. Required when type is 'json_schema'.","type":"object","required":["name","schema"],"properties":{"description":{"description":"A description of what the response format is for, used by the model to determine how to respond in the format.","type":"string"},"name":{"description":"A unique name identifier for this schema.","type":"string","pattern":"^[a-zA-Z0-9_-]+$","minLength":1},"strict":{"description":"When true, enforces strict schema adherence. The model will always follow the exact schema structure.\nWhen strict mode is enabled, the schema must follow these rules:\n- `additionalProperties: false` must be set on all object types\n- All properties must be listed in the `required` array\n- Maximum 100 properties total, with max 5 levels of nesting\n- Unsupported keywords: minLength, maxLength, pattern, minimum, maximum, minItems, maxItems\n- Root schema cannot use `anyOf` type\n","type":"boolean","nullable":true},"schema":{"description":"The JSON Schema definition that the model output must conform to.","type":"object","required":["type"],"properties":{"type":{"description":"The JSON type for this schema element.","type":"string","enum":["object","array","string","number","integer","boolean"]},"properties":{"description":"Property definitions when type is 'object'. Each key maps to a nested JsonSchemaDefinition.","type":"object","additionalProperties":{"description":"A JSON Schema definition for specifying data structure. Supports recursive schemas for nested objects.","type":"object","required":["type"],"properties":"circular()","title":"JsonSchemaDefinition"}},"required":{"description":"List of required property names when type is 'object'.","type":"array","items":{"type":"string"}},"additionalProperties":{"description":"Whether to allow additional properties beyond those defined.","type":"boolean","default":false},"items":{"description":"Schema for array items when type is 'array'.","type":"object","required":["type"],"properties":"circular()","title":"JsonSchemaDefinition"},"enum":{"description":"Allowed values for this schema element.","type":"array"},"description":{"description":"Human-readable description of this schema element.","type":"string"}},"title":"JsonSchemaDefinition"}},"title":"JsonSchemaSpec"}},"title":"ResponseFormat"}},"additionalProperties":true,"title":"CreateChatCompletionRequest"}}}}}
>
  
</RequestSchema>

<StatusCodes
  id={undefined}
  label={undefined}
  responses={{"200":{"description":"A chat completion","content":{"application/json":{"schema":{"description":"Response object containing the generated chat completion.","type":"object","required":["object","choices"],"properties":{"object":{"type":"string","enum":["chat.completion"],"description":"The object type, which is always 'chat.completion'."},"choices":{"type":"array","description":"A list of chat completion choices. Can be more than one if `n` is greater than `1`.","items":{"description":"A single chat completion choice returned in the response","type":"object","required":["index","message"],"properties":{"index":{"type":"integer","description":"The index of the choice in the array of choices."},"message":{"description":"A message in the chat completion response from the assistant.","type":"object","required":["role"],"properties":{"role":{"type":"string","description":"The role of the author of this message, typically 'assistant' for responses."}},"additionalProperties":true,"title":"ChatCompletionResponseMessage"}},"additionalProperties":true,"title":"ChatCompletionResponseChoice"}}},"additionalProperties":true,"title":"CreateChatCompletionResponse"}},"text/event-stream":{"schema":{"description":"The response object for streaming chat completions in chunks.","type":"object","required":["object","choices"],"properties":{"object":{"type":"string","enum":["chat.completion.chunk"],"description":"The object type, which is always 'chat.completion.chunk' for streaming responses."},"choices":{"type":"array","description":"A list of chat completion chunks.","items":{"description":"A single chat completion chunk choice in a streaming response.","type":"object","required":["index","delta"],"properties":{"index":{"type":"integer","description":"The index of the choice in the array of choices."},"delta":{"description":"A partial message update to be merged with previous chunks in a streaming response.","type":"object","properties":{"role":{"type":"string","description":"The role of the author of this message, typically 'assistant' for responses."}},"additionalProperties":true,"title":"ChatCompletionStreamResponseDelta"}},"additionalProperties":true,"title":"ChatCompletionStreamResponseChoice"}}},"additionalProperties":true,"title":"CreateChatCompletionStreamResponse"}}}},"400":{"description":"Chat completion request was malformed.","content":{"application/json":{"schema":{"description":"Error returned when a request contains invalid parameters or violates schema validation.","type":"object","properties":{"field_errors":{"description":"The errors that relate to specific fields in the request.","type":"object","additionalProperties":{"type":"string"}},"messages":{"type":"array","items":{"title":"message","type":"string"}},"request_id":{"description":"The ID of the request that can be used to help Vectara support debug what went wrong.","type":"string"}},"title":"BadRequestError"}}}},"403":{"description":"Permissions do not allow creating a chat completion.","content":{"application/json":{"schema":{"description":"A general error response with an error code and message.","type":"object","properties":{"messages":{"description":"The messages describing why the error occurred.","type":"array","items":{"title":"message","type":"string","example":"Internal server error."}},"request_id":{"description":"The ID of the request that can be used to help Vectara support debug what went wrong.","type":"string"}},"title":"Error"}}}}}}
>
  
</StatusCodes>


      