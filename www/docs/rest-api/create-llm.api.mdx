---
id: create-llm
title: "Create an LLM"
description: "Integrate external Large Language Models (LLMs) into Vectara for Retrieval Augmented Generation (RAG) and chat. Connect OpenAI API-compatible models from providers like Anthropic, Azure, Google, or custom-hosted endpoints. Once created, reference your custom LLM by name in query generation parameters."
sidebar_label: "Create an LLM"
hide_title: true
hide_table_of_contents: true
api: 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
sidebar_class_name: "post api-method"
info_path: docs/rest-api/vectara-rest-api-v-2
custom_edit_url: null
---

import MethodEndpoint from "@theme/ApiExplorer/MethodEndpoint";
import ParamsDetails from "@theme/ParamsDetails";
import RequestSchema from "@theme/RequestSchema";
import StatusCodes from "@theme/StatusCodes";
import OperationTabs from "@theme/OperationTabs";
import TabItem from "@theme/TabItem";
import Heading from "@theme/Heading";

<Heading
  as={"h1"}
  className={"openapi__heading"}
  children={"Create an LLM"}
>
</Heading>

<MethodEndpoint
  method={"post"}
  path={"/v2/llms"}
  context={"endpoint"}
>
  
</MethodEndpoint>



Integrate external Large Language Models (LLMs) into Vectara for Retrieval Augmented Generation (RAG) and chat. Connect OpenAI API-compatible models from providers like Anthropic, Azure, Google, or custom-hosted endpoints. Once created, reference your custom LLM by name in query generation parameters.
- Connect external LLMs using OpenAI-compatible API format
- Configure multiple LLM providers for different use cases
- Override Vectara's built-in LLMs with your own models
- Use custom models for RAG, chat, and document summarization

**Example providers:**

### OpenAI

**Type:** `openai-compatible`
**Models:** GPT-4o, GPT-5
**Auth:** Bearer token

```json
{
  "type": "openai-compatible",
  "name": "my-gpt5",
  "model": "gpt-5",
  "uri": "https://api.openai.com/v1/chat/completions",
  "auth": {
    "type": "bearer",
    "token": "sk-..."
  }
}
```

### OpenAI Responses API

**Type**: openai-responses
**Models**: o1-preview, o1-mini, o3-mini (reasoning models)
**Auth**: Bearer token
**Note**: For reasoning models that don't support streaming

```json
{
  "type": "openai-responses",
  "name": "my-o1",
  "model": "o1-preview",
  "uri": "https://api.openai.com/v1/chat/completions",
  "auth": {
    "type": "bearer",
    "token": "sk-..."
  }
}
```

### Anthropic Claude

**Type:** `openai-compatible`
**Models:** claude-4-opus, claude-4-5-haiku, claude-4-5-sonnet
**Auth:** Bearer token with header

```json
{
  "type": "openai-compatible",
  "name": "my-claude",
  "model": "claude-sonnet-4-5-20250929",
  "uri": "https://api.anthropic.com/v1/messages",
  "auth": {
    "type": "bearer",
    "token": "sk-ant-..."
  },
  "headers": {
    "anthropic-version": "2023-06-01"
  }
}
```

### Azure OpenAI

**Type:** `openai-compatible`
**Models:** GPT-3.5, GPT-4 (Azure-deployed versions)
**Auth:** Custom header (api-key)

```json
{
  "type": "openai-compatible",
  "name": "my-azure-gpt4",
  "model": "gpt-4",
  "uri": "https://YOUR-RESOURCE.openai.azure.com/openai/deployments/YOUR-DEPLOYMENT/chat/completions?api-version=2024-02-15-preview",
  "auth": {
    "type": "header",
    "header": "api-key",
    "value": "your-azure-key"
  }
}
```

### Google Vertex AI (Gemini)

**Type:** `vertex-ai`
**Models:** gemini-2.5-pro, gemini-2.5-flash
**Auth:** Service account or API key

```json
{
  "type": "vertex-ai",
  "name": "my-gemini",
  "model": "gemini-1.5-pro",
  "uri": "https://us-central1-aiplatform.googleapis.com/v1/projects/YOUR-PROJECT/locations/us-central1/publishers/google/models/gemini-1.5-pro:generateContent",
  "auth": {
    "type": "service_account",
    "key_json": "{...service account JSON...}"
  }
}
```

### Custom OpenAI-Compatible

**Type:** `openai-compatible`
**Models:** Any self-hosted or custom LLM, such as OpenRouter.
**Auth:** Bearer or custom header

```json
{
  "type": "openai-compatible",
  "name": "my-custom-llm",
  "model": "llama-3-70b",
  "uri": "https://my-llm-endpoint.com/v1/chat/completions",
  "auth": {
    "type": "bearer",
    "token": "custom-token"
  }
}
```


<Heading
  id={"request"}
  as={"h2"}
  className={"openapi-tabs__heading"}
  children={"Request"}
>
</Heading>

<ParamsDetails
  parameters={[{"in":"header","name":"Request-Timeout","description":"The API will make a best effort to complete the request in the specified seconds or time out.","schema":{"type":"integer","minimum":1},"required":false},{"in":"header","name":"Request-Timeout-Millis","description":"The API will make a best effort to complete the request in the specified milliseconds or time out.","schema":{"type":"integer","minimum":1}}]}
>
  
</ParamsDetails>

<RequestSchema
  title={"Body"}
  body={{"content":{"application/json":{"schema":{"description":"Request to create a Large Language Model connection for generative capabilities.","type":"object","discriminator":{"propertyName":"type","mapping":{"openai-compatible":{"description":"Request to create an OpenAI-compatible Large Language Model connection.","type":"object","allOf":[{"description":"Common fields for OpenAI-compatible and Responses API LLM requests.","type":"object","properties":{"name":{"description":"Name to reference the LLM. This will be used in other endpoints (like query) when using this LLM. If this name conflicts with a global LLM (a LLM that is preconfigured with the Vectara platform), then it will override that LLM for all usages.","type":"string","example":"Claude 3.7 Sonnet","minLength":1,"maxLength":255},"description":{"description":"Description of the LLM.","type":"string","default":"","maxLength":1000,"nullable":false,"example":"The Anthropic Claude 3.7 Sonnet model"},"model":{"description":"The model name to use with the API (e.g. gpt-4, claude-2, etc). This is used in the API request to the remote LLM provider.","type":"string","example":"claude-3-7-sonnet-20250219"},"uri":{"description":"The URI endpoint for the API (can be OpenAI or any compatible API endpoint)","type":"string","format":"uri","example":"https://api.anthropic.com/v1/chat/completions"},"auth":{"type":"object","description":"Authentication configuration for an LLM","discriminator":{"propertyName":"type","mapping":{"bearer":{"type":"object","description":"Bearer token authentication","properties":{"type":{"description":"Must be \"bearer\" for bearer token auth","type":"string","default":"bearer","example":"bearer"},"token":{"description":"The bearer token to use for authentication","type":"string","example":"abcdef......"}},"required":["type","token"],"x-vectaraParents":["RemoteAuth","AnthropicAuth"],"title":"BearerAuth"},"header":{"type":"object","description":"Custom header-based authentication","properties":{"type":{"description":"Must be \"header\" for header-based auth","type":"string","default":"header","example":"header"},"header":{"description":"The header name to use (e.g. x-api-key)","type":"string","example":"x-api-key"},"value":{"description":"The header value to use","type":"string","example":"sk-ant....."}},"required":["type","header","value"],"x-vectaraParents":["RemoteAuth","AnthropicAuth"],"title":"HeaderAuth"}}},"oneOf":[{"type":"object","description":"Bearer token authentication","properties":{"type":{"description":"Must be \"bearer\" for bearer token auth","type":"string","default":"bearer","example":"bearer"},"token":{"description":"The bearer token to use for authentication","type":"string","example":"abcdef......"}},"required":["type","token"],"x-vectaraParents":["RemoteAuth","AnthropicAuth"],"title":"BearerAuth"},{"type":"object","description":"Custom header-based authentication","properties":{"type":{"description":"Must be \"header\" for header-based auth","type":"string","default":"header","example":"header"},"header":{"description":"The header name to use (e.g. x-api-key)","type":"string","example":"x-api-key"},"value":{"description":"The header value to use","type":"string","example":"sk-ant....."}},"required":["type","header","value"],"x-vectaraParents":["RemoteAuth","AnthropicAuth"],"title":"HeaderAuth"}],"required":["type"],"title":"RemoteAuth"},"headers":{"description":"Additional HTTP headers to include with requests to the LLM API.","type":"object","additionalProperties":{"type":"string"}},"test_model_parameters":{"description":"Any additional parameters that are required for the LLM during the test call.","type":"object","additionalProperties":true,"example":{"max_tokens":512}},"capabilities":{"description":"Capabilities of a Large Language Model.","type":"object","properties":{"image_support":{"description":"Whether the model supports image inputs.","type":"boolean"},"context_limit":{"description":"Maximum context window size in tokens.","type":"integer","format":"int32"},"tool_calling":{"description":"Whether the model supports tool/function calling.","type":"boolean"},"structured_outputs":{"description":"Whether the model supports structured output generation.","type":"boolean"},"requires_role_alternation":{"description":"Whether the model requires strict role alternation in conversations. When true, consecutive messages of the same role will be grouped together.","type":"boolean"}},"title":"LLMCapabilities"}},"required":["name","uri"],"title":"OpenAILLMRequestBase"},{"type":"object","properties":{"type":{"description":"Must be \"openai-compatible\" for OpenAI and OpenAI-compatible APIs (like Anthropic Claude, Azure OpenAI, etc)","type":"string","default":"openai-compatible"},"model":{"description":"The model name to use with the API (e.g. gpt-4, claude-2, etc). This is used in the API request to the remote LLM provider.","type":"string","minLength":1}},"required":["type","model"]}],"x-vectaraParents":["CreateLLMRequest"],"title":"CreateOpenAILLMRequest"},"openai-responses":{"description":"Request to create an OpenAI Responses API Large Language Model connection for reasoning models like o1, o3.","type":"object","allOf":[{"description":"Common fields for OpenAI-compatible and Responses API LLM requests.","type":"object","properties":{"name":{"description":"Name to reference the LLM. This will be used in other endpoints (like query) when using this LLM. If this name conflicts with a global LLM (a LLM that is preconfigured with the Vectara platform), then it will override that LLM for all usages.","type":"string","example":"Claude 3.7 Sonnet","minLength":1,"maxLength":255},"description":{"description":"Description of the LLM.","type":"string","default":"","maxLength":1000,"nullable":false,"example":"The Anthropic Claude 3.7 Sonnet model"},"model":{"description":"The model name to use with the API (e.g. gpt-4, claude-2, etc). This is used in the API request to the remote LLM provider.","type":"string","example":"claude-3-7-sonnet-20250219"},"uri":{"description":"The URI endpoint for the API (can be OpenAI or any compatible API endpoint)","type":"string","format":"uri","example":"https://api.anthropic.com/v1/chat/completions"},"auth":{"type":"object","description":"Authentication configuration for an LLM","discriminator":{"propertyName":"type","mapping":{"bearer":{"type":"object","description":"Bearer token authentication","properties":{"type":{"description":"Must be \"bearer\" for bearer token auth","type":"string","default":"bearer","example":"bearer"},"token":{"description":"The bearer token to use for authentication","type":"string","example":"abcdef......"}},"required":["type","token"],"x-vectaraParents":["RemoteAuth","AnthropicAuth"],"title":"BearerAuth"},"header":{"type":"object","description":"Custom header-based authentication","properties":{"type":{"description":"Must be \"header\" for header-based auth","type":"string","default":"header","example":"header"},"header":{"description":"The header name to use (e.g. x-api-key)","type":"string","example":"x-api-key"},"value":{"description":"The header value to use","type":"string","example":"sk-ant....."}},"required":["type","header","value"],"x-vectaraParents":["RemoteAuth","AnthropicAuth"],"title":"HeaderAuth"}}},"oneOf":[{"type":"object","description":"Bearer token authentication","properties":{"type":{"description":"Must be \"bearer\" for bearer token auth","type":"string","default":"bearer","example":"bearer"},"token":{"description":"The bearer token to use for authentication","type":"string","example":"abcdef......"}},"required":["type","token"],"x-vectaraParents":["RemoteAuth","AnthropicAuth"],"title":"BearerAuth"},{"type":"object","description":"Custom header-based authentication","properties":{"type":{"description":"Must be \"header\" for header-based auth","type":"string","default":"header","example":"header"},"header":{"description":"The header name to use (e.g. x-api-key)","type":"string","example":"x-api-key"},"value":{"description":"The header value to use","type":"string","example":"sk-ant....."}},"required":["type","header","value"],"x-vectaraParents":["RemoteAuth","AnthropicAuth"],"title":"HeaderAuth"}],"required":["type"],"title":"RemoteAuth"},"headers":{"description":"Additional HTTP headers to include with requests to the LLM API.","type":"object","additionalProperties":{"type":"string"}},"test_model_parameters":{"description":"Any additional parameters that are required for the LLM during the test call.","type":"object","additionalProperties":true,"example":{"max_tokens":512}},"capabilities":{"description":"Capabilities of a Large Language Model.","type":"object","properties":{"image_support":{"description":"Whether the model supports image inputs.","type":"boolean"},"context_limit":{"description":"Maximum context window size in tokens.","type":"integer","format":"int32"},"tool_calling":{"description":"Whether the model supports tool/function calling.","type":"boolean"},"structured_outputs":{"description":"Whether the model supports structured output generation.","type":"boolean"},"requires_role_alternation":{"description":"Whether the model requires strict role alternation in conversations. When true, consecutive messages of the same role will be grouped together.","type":"boolean"}},"title":"LLMCapabilities"}},"required":["name","uri"],"title":"OpenAILLMRequestBase"},{"type":"object","properties":{"type":{"description":"Must be \"openai-responses\" for OpenAI Responses API (reasoning models like o1, o3)","type":"string","default":"openai-responses"},"model":{"description":"The model name to use with the Responses API (e.g. o1-preview, o1-mini). This is used in the API request to the remote LLM provider.","type":"string","minLength":1}},"required":["type","model"]}],"x-vectaraParents":["CreateLLMRequest"],"title":"CreateOpenAIResponsesLLMRequest"},"vertex-ai":{"description":"Request to create a Vertex AI Large Language Model connection for Gemini models.","type":"object","properties":{"type":{"description":"Must be \"vertex-ai\" for Google Cloud Vertex AI Gemini models","type":"string","default":"vertex-ai"},"name":{"description":"Name to reference the LLM. This will be used in other endpoints (like query) when using this LLM. If this name conflicts with a global LLM (a LLM that is preconfigured with the Vectara platform), then it will override that LLM for all usages.","type":"string"},"description":{"description":"Description of the LLM.","type":"string","default":"","nullable":false},"model":{"description":"The model name to use (e.g. gemini-2.5-flash, gemini-2.5-pro, gemini-2.0-experimental-1219, etc).","type":"string"},"uri":{"description":"The URI endpoint for the Vertex AI API","type":"string","format":"uri","example":"https://aiplatform.googleapis.com/v1/projects/my-project/locations/us-central1"},"auth":{"description":"Authentication configuration for Vertex AI","type":"object","discriminator":{"propertyName":"type","mapping":{"api_key":{"description":"API key authentication for Vertex AI","type":"object","properties":{"type":{"description":"Must be \"api_key\" for API key authentication","type":"string","default":"api_key"},"api_key":{"description":"The Google Cloud API key for authentication","type":"string"}},"required":["type","api_key"],"x-vectaraParents":["VertexAiAuth"],"title":"VertexAiApiKeyAuth"},"service_account":{"description":"Service account authentication for Vertex AI","type":"object","properties":{"type":{"description":"Must be \"service_account\" for service account authentication","type":"string","default":"service_account"},"key_json":{"description":"The service account JSON key file contents as a string","type":"string"}},"required":["type","key_json"],"x-vectaraParents":["VertexAiAuth"],"title":"VertexAiServiceAccountAuth"}}},"oneOf":[{"description":"API key authentication for Vertex AI","type":"object","properties":{"type":{"description":"Must be \"api_key\" for API key authentication","type":"string","default":"api_key"},"api_key":{"description":"The Google Cloud API key for authentication","type":"string"}},"required":["type","api_key"],"x-vectaraParents":["VertexAiAuth"],"title":"VertexAiApiKeyAuth"},{"description":"Service account authentication for Vertex AI","type":"object","properties":{"type":{"description":"Must be \"service_account\" for service account authentication","type":"string","default":"service_account"},"key_json":{"description":"The service account JSON key file contents as a string","type":"string"}},"required":["type","key_json"],"x-vectaraParents":["VertexAiAuth"],"title":"VertexAiServiceAccountAuth"}],"required":["type"],"title":"VertexAiAuth"},"test_model_parameters":{"description":"Any additional parameters that are required for the LLM during the test call.","type":"object","additionalProperties":true},"capabilities":{"description":"Capabilities of a Large Language Model.","type":"object","properties":{"image_support":{"description":"Whether the model supports image inputs.","type":"boolean"},"context_limit":{"description":"Maximum context window size in tokens.","type":"integer","format":"int32"},"tool_calling":{"description":"Whether the model supports tool/function calling.","type":"boolean"},"structured_outputs":{"description":"Whether the model supports structured output generation.","type":"boolean"},"requires_role_alternation":{"description":"Whether the model requires strict role alternation in conversations. When true, consecutive messages of the same role will be grouped together.","type":"boolean"}},"title":"LLMCapabilities"}},"required":["type","name","model","uri","auth"],"x-vectaraParents":["CreateLLMRequest"],"title":"CreateVertexAILLMRequest"},"anthropic":{"description":"Request to create an Anthropic Large Language Model connection for Claude models (direct API, Bedrock, or Vertex).","type":"object","properties":{"type":{"description":"Must be \"anthropic\" for Anthropic Claude models","type":"string","default":"anthropic"},"name":{"description":"Name to reference the LLM. This will be used in other endpoints (like query) when using this LLM. If this name conflicts with a global LLM (a LLM that is preconfigured with the Vectara platform), then it will override that LLM for all usages.","type":"string"},"description":{"description":"Description of the LLM.","type":"string","default":"","nullable":false},"model":{"description":"The Claude model name to use (e.g. claude-3-5-sonnet-20241022, claude-3-opus-20240229, etc).","type":"string"},"uri":{"description":"Optional custom endpoint URI for the Anthropic API. Defaults to https://api.anthropic.com/v1/messages if not specified when using direct Anthropic API (header auth with x-api-key). Not required when using Bedrock or Vertex authentication as the endpoint is determined from region/project configuration.","type":"string","format":"uri","example":"https://api.anthropic.com/v1/messages","default":"https://api.anthropic.com/v1/messages"},"auth":{"type":"object","description":"Authentication configuration for Anthropic LLM via direct Anthropic API (use RemoteAuth with header \"x-api-key\"), AWS Bedrock, or GCP Vertex AI Model Garden","discriminator":{"propertyName":"type","mapping":{"bearer":{"type":"object","description":"Bearer token authentication","properties":{"type":{"description":"Must be \"bearer\" for bearer token auth","type":"string","default":"bearer","example":"bearer"},"token":{"description":"The bearer token to use for authentication","type":"string","example":"abcdef......"}},"required":["type","token"],"x-vectaraParents":["RemoteAuth","AnthropicAuth"],"title":"BearerAuth"},"header":{"type":"object","description":"Custom header-based authentication","properties":{"type":{"description":"Must be \"header\" for header-based auth","type":"string","default":"header","example":"header"},"header":{"description":"The header name to use (e.g. x-api-key)","type":"string","example":"x-api-key"},"value":{"description":"The header value to use","type":"string","example":"sk-ant....."}},"required":["type","header","value"],"x-vectaraParents":["RemoteAuth","AnthropicAuth"],"title":"HeaderAuth"},"bedrock_static_iam":{"type":"object","description":"AWS Bedrock authentication with explicit IAM credentials","properties":{"type":{"description":"Must be \"bedrock_static_iam\" for static AWS IAM credentials","type":"string","default":"bedrock_static_iam","example":"bedrock_static_iam"},"aws_access_key_id":{"description":"AWS access key ID","type":"string","example":"AKIAIOSFODNN7EXAMPLE"},"aws_secret_access_key":{"description":"AWS secret access key","type":"string","example":"wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY"},"region":{"description":"AWS region for Bedrock","type":"string","example":"us-east-1"}},"required":["type","aws_access_key_id","aws_secret_access_key","region"],"x-vectaraParents":["AnthropicAuth"],"title":"BedrockStaticIAMAuth"},"bedrock_api_key":{"type":"object","description":"AWS Bedrock API key authentication","properties":{"type":{"description":"Must be \"bedrock_api_key\" for Bedrock API key auth","type":"string","default":"bedrock_api_key","example":"bedrock_api_key"},"api_key":{"description":"The Bedrock API key","type":"string","example":"AWS_BEARER_TOKEN_BEDROCK_..."},"region":{"description":"AWS region for Bedrock","type":"string","example":"us-east-1"}},"required":["type","api_key","region"],"x-vectaraParents":["AnthropicAuth"],"title":"BedrockApiKeyAuth"},"vertex_service_account":{"type":"object","description":"Google Cloud Vertex AI service account authentication","properties":{"type":{"description":"Must be \"vertex_service_account\" for service account auth","type":"string","default":"vertex_service_account","example":"vertex_service_account"},"key_json":{"description":"The service account key JSON","type":"string","example":"{\"type\":\"service_account\",\"project_id\":\"my-project\",...}"},"project":{"description":"GCP project ID","type":"string","example":"my-project-id"},"region":{"description":"GCP region for Vertex AI","type":"string","example":"us-central1"}},"required":["type","key_json","project","region"],"x-vectaraParents":["AnthropicAuth"],"title":"VertexServiceAccountAuth"},"vertex_access_token":{"type":"object","description":"Google Cloud Vertex AI access token authentication","properties":{"type":{"description":"Must be \"vertex_access_token\" for access token auth","type":"string","default":"vertex_access_token","example":"vertex_access_token"},"access_token":{"description":"The GCP access token","type":"string","example":"ya29.c.Kp..."},"project":{"description":"GCP project ID","type":"string","example":"my-project-id"},"region":{"description":"GCP region for Vertex AI","type":"string","example":"us-central1"}},"required":["type","access_token","project","region"],"x-vectaraParents":["AnthropicAuth"],"title":"VertexAccessTokenAuth"}}},"oneOf":[{"type":"object","description":"Bearer token authentication","properties":{"type":{"description":"Must be \"bearer\" for bearer token auth","type":"string","default":"bearer","example":"bearer"},"token":{"description":"The bearer token to use for authentication","type":"string","example":"abcdef......"}},"required":["type","token"],"x-vectaraParents":["RemoteAuth","AnthropicAuth"],"title":"BearerAuth"},{"type":"object","description":"Custom header-based authentication","properties":{"type":{"description":"Must be \"header\" for header-based auth","type":"string","default":"header","example":"header"},"header":{"description":"The header name to use (e.g. x-api-key)","type":"string","example":"x-api-key"},"value":{"description":"The header value to use","type":"string","example":"sk-ant....."}},"required":["type","header","value"],"x-vectaraParents":["RemoteAuth","AnthropicAuth"],"title":"HeaderAuth"},{"type":"object","description":"AWS Bedrock authentication with explicit IAM credentials","properties":{"type":{"description":"Must be \"bedrock_static_iam\" for static AWS IAM credentials","type":"string","default":"bedrock_static_iam","example":"bedrock_static_iam"},"aws_access_key_id":{"description":"AWS access key ID","type":"string","example":"AKIAIOSFODNN7EXAMPLE"},"aws_secret_access_key":{"description":"AWS secret access key","type":"string","example":"wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY"},"region":{"description":"AWS region for Bedrock","type":"string","example":"us-east-1"}},"required":["type","aws_access_key_id","aws_secret_access_key","region"],"x-vectaraParents":["AnthropicAuth"],"title":"BedrockStaticIAMAuth"},{"type":"object","description":"AWS Bedrock API key authentication","properties":{"type":{"description":"Must be \"bedrock_api_key\" for Bedrock API key auth","type":"string","default":"bedrock_api_key","example":"bedrock_api_key"},"api_key":{"description":"The Bedrock API key","type":"string","example":"AWS_BEARER_TOKEN_BEDROCK_..."},"region":{"description":"AWS region for Bedrock","type":"string","example":"us-east-1"}},"required":["type","api_key","region"],"x-vectaraParents":["AnthropicAuth"],"title":"BedrockApiKeyAuth"},{"type":"object","description":"Google Cloud Vertex AI service account authentication","properties":{"type":{"description":"Must be \"vertex_service_account\" for service account auth","type":"string","default":"vertex_service_account","example":"vertex_service_account"},"key_json":{"description":"The service account key JSON","type":"string","example":"{\"type\":\"service_account\",\"project_id\":\"my-project\",...}"},"project":{"description":"GCP project ID","type":"string","example":"my-project-id"},"region":{"description":"GCP region for Vertex AI","type":"string","example":"us-central1"}},"required":["type","key_json","project","region"],"x-vectaraParents":["AnthropicAuth"],"title":"VertexServiceAccountAuth"},{"type":"object","description":"Google Cloud Vertex AI access token authentication","properties":{"type":{"description":"Must be \"vertex_access_token\" for access token auth","type":"string","default":"vertex_access_token","example":"vertex_access_token"},"access_token":{"description":"The GCP access token","type":"string","example":"ya29.c.Kp..."},"project":{"description":"GCP project ID","type":"string","example":"my-project-id"},"region":{"description":"GCP region for Vertex AI","type":"string","example":"us-central1"}},"required":["type","access_token","project","region"],"x-vectaraParents":["AnthropicAuth"],"title":"VertexAccessTokenAuth"}],"required":["type"],"title":"AnthropicAuth"},"headers":{"description":"Optional additional headers to send with the request","type":"object","additionalProperties":{"type":"string"}},"test_model_parameters":{"description":"Any additional parameters that are required for the LLM during the test call.","type":"object","additionalProperties":true},"capabilities":{"description":"Capabilities of a Large Language Model.","type":"object","properties":{"image_support":{"description":"Whether the model supports image inputs.","type":"boolean"},"context_limit":{"description":"Maximum context window size in tokens.","type":"integer","format":"int32"},"tool_calling":{"description":"Whether the model supports tool/function calling.","type":"boolean"},"structured_outputs":{"description":"Whether the model supports structured output generation.","type":"boolean"},"requires_role_alternation":{"description":"Whether the model requires strict role alternation in conversations. When true, consecutive messages of the same role will be grouped together.","type":"boolean"}},"title":"LLMCapabilities"}},"required":["type","name","model","auth"],"x-vectaraParents":["CreateLLMRequest"],"title":"CreateAnthropicLLMRequest"}}},"oneOf":[{"description":"Request to create an OpenAI-compatible Large Language Model connection.","type":"object","allOf":[{"description":"Common fields for OpenAI-compatible and Responses API LLM requests.","type":"object","properties":{"name":{"description":"Name to reference the LLM. This will be used in other endpoints (like query) when using this LLM. If this name conflicts with a global LLM (a LLM that is preconfigured with the Vectara platform), then it will override that LLM for all usages.","type":"string","example":"Claude 3.7 Sonnet","minLength":1,"maxLength":255},"description":{"description":"Description of the LLM.","type":"string","default":"","maxLength":1000,"nullable":false,"example":"The Anthropic Claude 3.7 Sonnet model"},"model":{"description":"The model name to use with the API (e.g. gpt-4, claude-2, etc). This is used in the API request to the remote LLM provider.","type":"string","example":"claude-3-7-sonnet-20250219"},"uri":{"description":"The URI endpoint for the API (can be OpenAI or any compatible API endpoint)","type":"string","format":"uri","example":"https://api.anthropic.com/v1/chat/completions"},"auth":{"type":"object","description":"Authentication configuration for an LLM","discriminator":{"propertyName":"type","mapping":{"bearer":{"type":"object","description":"Bearer token authentication","properties":{"type":{"description":"Must be \"bearer\" for bearer token auth","type":"string","default":"bearer","example":"bearer"},"token":{"description":"The bearer token to use for authentication","type":"string","example":"abcdef......"}},"required":["type","token"],"x-vectaraParents":["RemoteAuth","AnthropicAuth"],"title":"BearerAuth"},"header":{"type":"object","description":"Custom header-based authentication","properties":{"type":{"description":"Must be \"header\" for header-based auth","type":"string","default":"header","example":"header"},"header":{"description":"The header name to use (e.g. x-api-key)","type":"string","example":"x-api-key"},"value":{"description":"The header value to use","type":"string","example":"sk-ant....."}},"required":["type","header","value"],"x-vectaraParents":["RemoteAuth","AnthropicAuth"],"title":"HeaderAuth"}}},"oneOf":[{"type":"object","description":"Bearer token authentication","properties":{"type":{"description":"Must be \"bearer\" for bearer token auth","type":"string","default":"bearer","example":"bearer"},"token":{"description":"The bearer token to use for authentication","type":"string","example":"abcdef......"}},"required":["type","token"],"x-vectaraParents":["RemoteAuth","AnthropicAuth"],"title":"BearerAuth"},{"type":"object","description":"Custom header-based authentication","properties":{"type":{"description":"Must be \"header\" for header-based auth","type":"string","default":"header","example":"header"},"header":{"description":"The header name to use (e.g. x-api-key)","type":"string","example":"x-api-key"},"value":{"description":"The header value to use","type":"string","example":"sk-ant....."}},"required":["type","header","value"],"x-vectaraParents":["RemoteAuth","AnthropicAuth"],"title":"HeaderAuth"}],"required":["type"],"title":"RemoteAuth"},"headers":{"description":"Additional HTTP headers to include with requests to the LLM API.","type":"object","additionalProperties":{"type":"string"}},"test_model_parameters":{"description":"Any additional parameters that are required for the LLM during the test call.","type":"object","additionalProperties":true,"example":{"max_tokens":512}},"capabilities":{"description":"Capabilities of a Large Language Model.","type":"object","properties":{"image_support":{"description":"Whether the model supports image inputs.","type":"boolean"},"context_limit":{"description":"Maximum context window size in tokens.","type":"integer","format":"int32"},"tool_calling":{"description":"Whether the model supports tool/function calling.","type":"boolean"},"structured_outputs":{"description":"Whether the model supports structured output generation.","type":"boolean"},"requires_role_alternation":{"description":"Whether the model requires strict role alternation in conversations. When true, consecutive messages of the same role will be grouped together.","type":"boolean"}},"title":"LLMCapabilities"}},"required":["name","uri"],"title":"OpenAILLMRequestBase"},{"type":"object","properties":{"type":{"description":"Must be \"openai-compatible\" for OpenAI and OpenAI-compatible APIs (like Anthropic Claude, Azure OpenAI, etc)","type":"string","default":"openai-compatible"},"model":{"description":"The model name to use with the API (e.g. gpt-4, claude-2, etc). This is used in the API request to the remote LLM provider.","type":"string","minLength":1}},"required":["type","model"]}],"x-vectaraParents":["CreateLLMRequest"],"title":"CreateOpenAILLMRequest"},{"description":"Request to create an OpenAI Responses API Large Language Model connection for reasoning models like o1, o3.","type":"object","allOf":[{"description":"Common fields for OpenAI-compatible and Responses API LLM requests.","type":"object","properties":{"name":{"description":"Name to reference the LLM. This will be used in other endpoints (like query) when using this LLM. If this name conflicts with a global LLM (a LLM that is preconfigured with the Vectara platform), then it will override that LLM for all usages.","type":"string","example":"Claude 3.7 Sonnet","minLength":1,"maxLength":255},"description":{"description":"Description of the LLM.","type":"string","default":"","maxLength":1000,"nullable":false,"example":"The Anthropic Claude 3.7 Sonnet model"},"model":{"description":"The model name to use with the API (e.g. gpt-4, claude-2, etc). This is used in the API request to the remote LLM provider.","type":"string","example":"claude-3-7-sonnet-20250219"},"uri":{"description":"The URI endpoint for the API (can be OpenAI or any compatible API endpoint)","type":"string","format":"uri","example":"https://api.anthropic.com/v1/chat/completions"},"auth":{"type":"object","description":"Authentication configuration for an LLM","discriminator":{"propertyName":"type","mapping":{"bearer":{"type":"object","description":"Bearer token authentication","properties":{"type":{"description":"Must be \"bearer\" for bearer token auth","type":"string","default":"bearer","example":"bearer"},"token":{"description":"The bearer token to use for authentication","type":"string","example":"abcdef......"}},"required":["type","token"],"x-vectaraParents":["RemoteAuth","AnthropicAuth"],"title":"BearerAuth"},"header":{"type":"object","description":"Custom header-based authentication","properties":{"type":{"description":"Must be \"header\" for header-based auth","type":"string","default":"header","example":"header"},"header":{"description":"The header name to use (e.g. x-api-key)","type":"string","example":"x-api-key"},"value":{"description":"The header value to use","type":"string","example":"sk-ant....."}},"required":["type","header","value"],"x-vectaraParents":["RemoteAuth","AnthropicAuth"],"title":"HeaderAuth"}}},"oneOf":[{"type":"object","description":"Bearer token authentication","properties":{"type":{"description":"Must be \"bearer\" for bearer token auth","type":"string","default":"bearer","example":"bearer"},"token":{"description":"The bearer token to use for authentication","type":"string","example":"abcdef......"}},"required":["type","token"],"x-vectaraParents":["RemoteAuth","AnthropicAuth"],"title":"BearerAuth"},{"type":"object","description":"Custom header-based authentication","properties":{"type":{"description":"Must be \"header\" for header-based auth","type":"string","default":"header","example":"header"},"header":{"description":"The header name to use (e.g. x-api-key)","type":"string","example":"x-api-key"},"value":{"description":"The header value to use","type":"string","example":"sk-ant....."}},"required":["type","header","value"],"x-vectaraParents":["RemoteAuth","AnthropicAuth"],"title":"HeaderAuth"}],"required":["type"],"title":"RemoteAuth"},"headers":{"description":"Additional HTTP headers to include with requests to the LLM API.","type":"object","additionalProperties":{"type":"string"}},"test_model_parameters":{"description":"Any additional parameters that are required for the LLM during the test call.","type":"object","additionalProperties":true,"example":{"max_tokens":512}},"capabilities":{"description":"Capabilities of a Large Language Model.","type":"object","properties":{"image_support":{"description":"Whether the model supports image inputs.","type":"boolean"},"context_limit":{"description":"Maximum context window size in tokens.","type":"integer","format":"int32"},"tool_calling":{"description":"Whether the model supports tool/function calling.","type":"boolean"},"structured_outputs":{"description":"Whether the model supports structured output generation.","type":"boolean"},"requires_role_alternation":{"description":"Whether the model requires strict role alternation in conversations. When true, consecutive messages of the same role will be grouped together.","type":"boolean"}},"title":"LLMCapabilities"}},"required":["name","uri"],"title":"OpenAILLMRequestBase"},{"type":"object","properties":{"type":{"description":"Must be \"openai-responses\" for OpenAI Responses API (reasoning models like o1, o3)","type":"string","default":"openai-responses"},"model":{"description":"The model name to use with the Responses API (e.g. o1-preview, o1-mini). This is used in the API request to the remote LLM provider.","type":"string","minLength":1}},"required":["type","model"]}],"x-vectaraParents":["CreateLLMRequest"],"title":"CreateOpenAIResponsesLLMRequest"},{"description":"Request to create a Vertex AI Large Language Model connection for Gemini models.","type":"object","properties":{"type":{"description":"Must be \"vertex-ai\" for Google Cloud Vertex AI Gemini models","type":"string","default":"vertex-ai"},"name":{"description":"Name to reference the LLM. This will be used in other endpoints (like query) when using this LLM. If this name conflicts with a global LLM (a LLM that is preconfigured with the Vectara platform), then it will override that LLM for all usages.","type":"string"},"description":{"description":"Description of the LLM.","type":"string","default":"","nullable":false},"model":{"description":"The model name to use (e.g. gemini-2.5-flash, gemini-2.5-pro, gemini-2.0-experimental-1219, etc).","type":"string"},"uri":{"description":"The URI endpoint for the Vertex AI API","type":"string","format":"uri","example":"https://aiplatform.googleapis.com/v1/projects/my-project/locations/us-central1"},"auth":{"description":"Authentication configuration for Vertex AI","type":"object","discriminator":{"propertyName":"type","mapping":{"api_key":{"description":"API key authentication for Vertex AI","type":"object","properties":{"type":{"description":"Must be \"api_key\" for API key authentication","type":"string","default":"api_key"},"api_key":{"description":"The Google Cloud API key for authentication","type":"string"}},"required":["type","api_key"],"x-vectaraParents":["VertexAiAuth"],"title":"VertexAiApiKeyAuth"},"service_account":{"description":"Service account authentication for Vertex AI","type":"object","properties":{"type":{"description":"Must be \"service_account\" for service account authentication","type":"string","default":"service_account"},"key_json":{"description":"The service account JSON key file contents as a string","type":"string"}},"required":["type","key_json"],"x-vectaraParents":["VertexAiAuth"],"title":"VertexAiServiceAccountAuth"}}},"oneOf":[{"description":"API key authentication for Vertex AI","type":"object","properties":{"type":{"description":"Must be \"api_key\" for API key authentication","type":"string","default":"api_key"},"api_key":{"description":"The Google Cloud API key for authentication","type":"string"}},"required":["type","api_key"],"x-vectaraParents":["VertexAiAuth"],"title":"VertexAiApiKeyAuth"},{"description":"Service account authentication for Vertex AI","type":"object","properties":{"type":{"description":"Must be \"service_account\" for service account authentication","type":"string","default":"service_account"},"key_json":{"description":"The service account JSON key file contents as a string","type":"string"}},"required":["type","key_json"],"x-vectaraParents":["VertexAiAuth"],"title":"VertexAiServiceAccountAuth"}],"required":["type"],"title":"VertexAiAuth"},"test_model_parameters":{"description":"Any additional parameters that are required for the LLM during the test call.","type":"object","additionalProperties":true},"capabilities":{"description":"Capabilities of a Large Language Model.","type":"object","properties":{"image_support":{"description":"Whether the model supports image inputs.","type":"boolean"},"context_limit":{"description":"Maximum context window size in tokens.","type":"integer","format":"int32"},"tool_calling":{"description":"Whether the model supports tool/function calling.","type":"boolean"},"structured_outputs":{"description":"Whether the model supports structured output generation.","type":"boolean"},"requires_role_alternation":{"description":"Whether the model requires strict role alternation in conversations. When true, consecutive messages of the same role will be grouped together.","type":"boolean"}},"title":"LLMCapabilities"}},"required":["type","name","model","uri","auth"],"x-vectaraParents":["CreateLLMRequest"],"title":"CreateVertexAILLMRequest"},{"description":"Request to create an Anthropic Large Language Model connection for Claude models (direct API, Bedrock, or Vertex).","type":"object","properties":{"type":{"description":"Must be \"anthropic\" for Anthropic Claude models","type":"string","default":"anthropic"},"name":{"description":"Name to reference the LLM. This will be used in other endpoints (like query) when using this LLM. If this name conflicts with a global LLM (a LLM that is preconfigured with the Vectara platform), then it will override that LLM for all usages.","type":"string"},"description":{"description":"Description of the LLM.","type":"string","default":"","nullable":false},"model":{"description":"The Claude model name to use (e.g. claude-3-5-sonnet-20241022, claude-3-opus-20240229, etc).","type":"string"},"uri":{"description":"Optional custom endpoint URI for the Anthropic API. Defaults to https://api.anthropic.com/v1/messages if not specified when using direct Anthropic API (header auth with x-api-key). Not required when using Bedrock or Vertex authentication as the endpoint is determined from region/project configuration.","type":"string","format":"uri","example":"https://api.anthropic.com/v1/messages","default":"https://api.anthropic.com/v1/messages"},"auth":{"type":"object","description":"Authentication configuration for Anthropic LLM via direct Anthropic API (use RemoteAuth with header \"x-api-key\"), AWS Bedrock, or GCP Vertex AI Model Garden","discriminator":{"propertyName":"type","mapping":{"bearer":{"type":"object","description":"Bearer token authentication","properties":{"type":{"description":"Must be \"bearer\" for bearer token auth","type":"string","default":"bearer","example":"bearer"},"token":{"description":"The bearer token to use for authentication","type":"string","example":"abcdef......"}},"required":["type","token"],"x-vectaraParents":["RemoteAuth","AnthropicAuth"],"title":"BearerAuth"},"header":{"type":"object","description":"Custom header-based authentication","properties":{"type":{"description":"Must be \"header\" for header-based auth","type":"string","default":"header","example":"header"},"header":{"description":"The header name to use (e.g. x-api-key)","type":"string","example":"x-api-key"},"value":{"description":"The header value to use","type":"string","example":"sk-ant....."}},"required":["type","header","value"],"x-vectaraParents":["RemoteAuth","AnthropicAuth"],"title":"HeaderAuth"},"bedrock_static_iam":{"type":"object","description":"AWS Bedrock authentication with explicit IAM credentials","properties":{"type":{"description":"Must be \"bedrock_static_iam\" for static AWS IAM credentials","type":"string","default":"bedrock_static_iam","example":"bedrock_static_iam"},"aws_access_key_id":{"description":"AWS access key ID","type":"string","example":"AKIAIOSFODNN7EXAMPLE"},"aws_secret_access_key":{"description":"AWS secret access key","type":"string","example":"wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY"},"region":{"description":"AWS region for Bedrock","type":"string","example":"us-east-1"}},"required":["type","aws_access_key_id","aws_secret_access_key","region"],"x-vectaraParents":["AnthropicAuth"],"title":"BedrockStaticIAMAuth"},"bedrock_api_key":{"type":"object","description":"AWS Bedrock API key authentication","properties":{"type":{"description":"Must be \"bedrock_api_key\" for Bedrock API key auth","type":"string","default":"bedrock_api_key","example":"bedrock_api_key"},"api_key":{"description":"The Bedrock API key","type":"string","example":"AWS_BEARER_TOKEN_BEDROCK_..."},"region":{"description":"AWS region for Bedrock","type":"string","example":"us-east-1"}},"required":["type","api_key","region"],"x-vectaraParents":["AnthropicAuth"],"title":"BedrockApiKeyAuth"},"vertex_service_account":{"type":"object","description":"Google Cloud Vertex AI service account authentication","properties":{"type":{"description":"Must be \"vertex_service_account\" for service account auth","type":"string","default":"vertex_service_account","example":"vertex_service_account"},"key_json":{"description":"The service account key JSON","type":"string","example":"{\"type\":\"service_account\",\"project_id\":\"my-project\",...}"},"project":{"description":"GCP project ID","type":"string","example":"my-project-id"},"region":{"description":"GCP region for Vertex AI","type":"string","example":"us-central1"}},"required":["type","key_json","project","region"],"x-vectaraParents":["AnthropicAuth"],"title":"VertexServiceAccountAuth"},"vertex_access_token":{"type":"object","description":"Google Cloud Vertex AI access token authentication","properties":{"type":{"description":"Must be \"vertex_access_token\" for access token auth","type":"string","default":"vertex_access_token","example":"vertex_access_token"},"access_token":{"description":"The GCP access token","type":"string","example":"ya29.c.Kp..."},"project":{"description":"GCP project ID","type":"string","example":"my-project-id"},"region":{"description":"GCP region for Vertex AI","type":"string","example":"us-central1"}},"required":["type","access_token","project","region"],"x-vectaraParents":["AnthropicAuth"],"title":"VertexAccessTokenAuth"}}},"oneOf":[{"type":"object","description":"Bearer token authentication","properties":{"type":{"description":"Must be \"bearer\" for bearer token auth","type":"string","default":"bearer","example":"bearer"},"token":{"description":"The bearer token to use for authentication","type":"string","example":"abcdef......"}},"required":["type","token"],"x-vectaraParents":["RemoteAuth","AnthropicAuth"],"title":"BearerAuth"},{"type":"object","description":"Custom header-based authentication","properties":{"type":{"description":"Must be \"header\" for header-based auth","type":"string","default":"header","example":"header"},"header":{"description":"The header name to use (e.g. x-api-key)","type":"string","example":"x-api-key"},"value":{"description":"The header value to use","type":"string","example":"sk-ant....."}},"required":["type","header","value"],"x-vectaraParents":["RemoteAuth","AnthropicAuth"],"title":"HeaderAuth"},{"type":"object","description":"AWS Bedrock authentication with explicit IAM credentials","properties":{"type":{"description":"Must be \"bedrock_static_iam\" for static AWS IAM credentials","type":"string","default":"bedrock_static_iam","example":"bedrock_static_iam"},"aws_access_key_id":{"description":"AWS access key ID","type":"string","example":"AKIAIOSFODNN7EXAMPLE"},"aws_secret_access_key":{"description":"AWS secret access key","type":"string","example":"wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY"},"region":{"description":"AWS region for Bedrock","type":"string","example":"us-east-1"}},"required":["type","aws_access_key_id","aws_secret_access_key","region"],"x-vectaraParents":["AnthropicAuth"],"title":"BedrockStaticIAMAuth"},{"type":"object","description":"AWS Bedrock API key authentication","properties":{"type":{"description":"Must be \"bedrock_api_key\" for Bedrock API key auth","type":"string","default":"bedrock_api_key","example":"bedrock_api_key"},"api_key":{"description":"The Bedrock API key","type":"string","example":"AWS_BEARER_TOKEN_BEDROCK_..."},"region":{"description":"AWS region for Bedrock","type":"string","example":"us-east-1"}},"required":["type","api_key","region"],"x-vectaraParents":["AnthropicAuth"],"title":"BedrockApiKeyAuth"},{"type":"object","description":"Google Cloud Vertex AI service account authentication","properties":{"type":{"description":"Must be \"vertex_service_account\" for service account auth","type":"string","default":"vertex_service_account","example":"vertex_service_account"},"key_json":{"description":"The service account key JSON","type":"string","example":"{\"type\":\"service_account\",\"project_id\":\"my-project\",...}"},"project":{"description":"GCP project ID","type":"string","example":"my-project-id"},"region":{"description":"GCP region for Vertex AI","type":"string","example":"us-central1"}},"required":["type","key_json","project","region"],"x-vectaraParents":["AnthropicAuth"],"title":"VertexServiceAccountAuth"},{"type":"object","description":"Google Cloud Vertex AI access token authentication","properties":{"type":{"description":"Must be \"vertex_access_token\" for access token auth","type":"string","default":"vertex_access_token","example":"vertex_access_token"},"access_token":{"description":"The GCP access token","type":"string","example":"ya29.c.Kp..."},"project":{"description":"GCP project ID","type":"string","example":"my-project-id"},"region":{"description":"GCP region for Vertex AI","type":"string","example":"us-central1"}},"required":["type","access_token","project","region"],"x-vectaraParents":["AnthropicAuth"],"title":"VertexAccessTokenAuth"}],"required":["type"],"title":"AnthropicAuth"},"headers":{"description":"Optional additional headers to send with the request","type":"object","additionalProperties":{"type":"string"}},"test_model_parameters":{"description":"Any additional parameters that are required for the LLM during the test call.","type":"object","additionalProperties":true},"capabilities":{"description":"Capabilities of a Large Language Model.","type":"object","properties":{"image_support":{"description":"Whether the model supports image inputs.","type":"boolean"},"context_limit":{"description":"Maximum context window size in tokens.","type":"integer","format":"int32"},"tool_calling":{"description":"Whether the model supports tool/function calling.","type":"boolean"},"structured_outputs":{"description":"Whether the model supports structured output generation.","type":"boolean"},"requires_role_alternation":{"description":"Whether the model requires strict role alternation in conversations. When true, consecutive messages of the same role will be grouped together.","type":"boolean"}},"title":"LLMCapabilities"}},"required":["type","name","model","auth"],"x-vectaraParents":["CreateLLMRequest"],"title":"CreateAnthropicLLMRequest"}],"required":["type"],"title":"CreateLLMRequest"}}}}}
>
  
</RequestSchema>

<StatusCodes
  id={undefined}
  label={undefined}
  responses={{"201":{"description":"The LLM has been created","content":{"application/json":{"schema":{"description":"A LLM can be used to enhance query results with a response, and be used as the responder during a chat.","type":"object","properties":{"id":{"description":"The ID of the LLM.","type":"string","pattern":"llm_.*","example":"llm_1021844"},"name":{"description":"Name of the LLM.","type":"string","example":"Claude 3.7 Sonnet"},"description":{"description":"The description of the LLM.","type":"string","example":"The Anthropic Claude 3.7 Sonnet model."},"enabled":{"description":"Indicates whether the LLM is enabled.","type":"boolean"},"default":{"description":"If this is the default LLM, it is used in queries when the generator is not specified.","type":"boolean"},"capabilities":{"description":"Capabilities of a Large Language Model.","type":"object","properties":{"image_support":{"description":"Whether the model supports image inputs.","type":"boolean"},"context_limit":{"description":"Maximum context window size in tokens.","type":"integer","format":"int32"},"tool_calling":{"description":"Whether the model supports tool/function calling.","type":"boolean"},"structured_outputs":{"description":"Whether the model supports structured output generation.","type":"boolean"},"requires_role_alternation":{"description":"Whether the model requires strict role alternation in conversations. When true, consecutive messages of the same role will be grouped together.","type":"boolean"}},"title":"LLMCapabilities"},"prompts":{"description":"List of prompts that the model can use. This is deprecated; see `/v2/generation_presets` instead.","items":{"description":"A prompt that can be used with a LLM. A prompt is the template that is used to render the text sent to the LLM. It also contains various default model settings such as temperature.","type":"object","properties":{"id":{"description":"The ID of the prompt.","type":"string","pattern":"pmt_.*"},"name":{"description":"Name of the prompt. This is used as the `prompt_name` in a query.","type":"string"},"description":{"description":"The description of the prompt.","type":"string"},"enabled":{"description":"Indicates whether the prompt is enabled.","type":"boolean"},"default":{"description":"Indicates if this prompt is the default prompt used with the LLM.","type":"boolean"}},"title":"Prompt"},"deprecated":true}},"title":"LLM"}}}},"400":{"description":"Invalid request body","content":{"application/json":{"schema":{"description":"Error returned when a request contains invalid parameters or violates schema validation.","type":"object","properties":{"field_errors":{"description":"The errors that relate to specific fields in the request.","type":"object","additionalProperties":{"type":"string"}},"messages":{"type":"array","items":{"title":"message","type":"string"}},"request_id":{"description":"The ID of the request that can be used to help Vectara support debug what went wrong.","type":"string"}},"title":"BadRequestError"}}}},"403":{"description":"Permissions do not allow creating an LLM","content":{"application/json":{"schema":{"description":"A general error response with an error code and message.","type":"object","properties":{"messages":{"description":"The messages describing why the error occurred.","type":"array","items":{"title":"message","type":"string","example":"Internal server error."}},"request_id":{"description":"The ID of the request that can be used to help Vectara support debug what went wrong.","type":"string"}},"title":"Error"}}}}}}
>
  
</StatusCodes>


      